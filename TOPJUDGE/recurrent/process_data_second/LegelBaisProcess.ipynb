{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thulac\n",
    "import jieba\n",
    "import json\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "add_punc='，。、【 】 “”：；（）《》‘’{}？！⑦()、%^>℃：.”“^-——=&#@￥'\n",
    "all_punc = punctuation + add_punc\n",
    "doc_len = 15\n",
    "sent_len = 100\n",
    "\n",
    "\n",
    "def punc_delete(fact_list):\n",
    "    fact_filtered = []\n",
    "    for word in fact_list:\n",
    "        fact_filtered.append(word)\n",
    "        if word in all_punc:\n",
    "            fact_filtered.remove(word)\n",
    "    return fact_filtered\n",
    "\n",
    "\n",
    "def hanzi_to_num(hanzi_1):\n",
    "    # for num<10000\n",
    "    hanzi = hanzi_1.strip().replace('零', '')\n",
    "    if hanzi == '':\n",
    "        return str(int(0))\n",
    "    d = {'一': 1, '二': 2, '三': 3, '四': 4, '五': 5, '六': 6, '七': 7, '八': 8, '九': 9, '': 0}\n",
    "    m = {'十': 1e1, '百': 1e2, '千': 1e3, }\n",
    "    w = {'万': 1e4, '亿': 1e8}\n",
    "    res = 0\n",
    "    tmp = 0\n",
    "    thou = 0\n",
    "    for i in hanzi:\n",
    "        if i not in d.keys() and i not in m.keys() and i not in w.keys():\n",
    "            return hanzi\n",
    "\n",
    "    if (hanzi[0]) == '十': hanzi = '一' + hanzi\n",
    "    for i in range(len(hanzi)):\n",
    "        if hanzi[i] in d:\n",
    "            tmp += d[hanzi[i]]\n",
    "        elif hanzi[i] in m:\n",
    "            tmp *= m[hanzi[i]]\n",
    "            res += tmp\n",
    "            tmp = 0\n",
    "        else:\n",
    "            thou += (res + tmp) * w[hanzi[i]]\n",
    "            tmp = 0\n",
    "            res = 0\n",
    "    return int(thou + res + tmp)\n",
    "\n",
    "\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "def get_cutter(dict_path=\"../law_tokenize/Thuocl_seg.txt\", mode='thulac', stop_words_filtered=True):\n",
    "    if stop_words_filtered:\n",
    "        stopwords = stopwordslist('../law_tokenize/stop_word.txt')  # 这里加载停用词的路径\n",
    "    else:\n",
    "        stopwords = []\n",
    "    if mode == 'jieba':\n",
    "        jieba.load_userdict(dict_path)\n",
    "        return lambda x: [a for a in list(jieba.cut(x)) if a not in stopwords]\n",
    "    elif mode == 'thulac':\n",
    "        thu = thulac.thulac(user_dict=dict_path, seg_only=True)\n",
    "        return lambda x: [a for a in thu.cut(x, text=True).split(' ') if a not in stopwords]\n",
    "\n",
    "\n",
    "def seg_sentence(sentence, cut):\n",
    "    # cut=get_cutter()\n",
    "    # sentence_seged = thu.cut(sentence.strip(), text=True).split(' ')\n",
    "    sentence_seged = cut(sentence)\n",
    "    # print(sentence_seged)\n",
    "    outstr = []\n",
    "    for word in sentence_seged:\n",
    "        if word != '\\t':\n",
    "            word = str(hanzi_to_num(word))\n",
    "            outstr.append(word)\n",
    "            # outstr += \" \"\n",
    "    return outstr\n",
    "\n",
    "\n",
    "def lookup_index_for_sentences(sentences, word2id, doc_len, sent_len):\n",
    "    item_num = 0\n",
    "    res = []\n",
    "    if len(sentences) == 0:\n",
    "        tmp = [word2id['BLANK']] * sent_len\n",
    "        res.append(np.array(tmp))\n",
    "    else:\n",
    "        for sent in sentences:\n",
    "            sent = punc_delete(sent)\n",
    "            tmp = [word2id['BLANK']] * sent_len\n",
    "            for i in range(len(sent)):\n",
    "                if i >= sent_len:\n",
    "                    break\n",
    "                try:\n",
    "                    tmp[i] = word2id[sent[i]]\n",
    "                    item_num += 1\n",
    "                except KeyError:\n",
    "                    tmp[i] = word2id['UNK']\n",
    "\n",
    "            res.append(np.array(tmp))\n",
    "    if len(res) < doc_len:\n",
    "        res = np.concatenate([np.array(res), word2id['BLANK'] * np.ones([doc_len - len(res), sent_len], dtype='int')], 0)\n",
    "    else:\n",
    "        res = np.array(res[:doc_len])\n",
    "\n",
    "    return res, item_num\n",
    "\n",
    "\n",
    "def sentence2index_matrix(sentence, word2id, doc_len, sent_len, cut):\n",
    "    sentence = sentence.replace(' ', '')\n",
    "    sent_words, sent_n_words = [], []\n",
    "    for i in sentence.split('。'):\n",
    "        if i != '':\n",
    "            sent_words.append((seg_sentence(i, cut)))\n",
    "    index_matrix, item_num = lookup_index_for_sentences(sent_words, word2id, doc_len, sent_len)\n",
    "    return index_matrix, item_num, sent_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "996\n",
      "再审 查明 的 犯罪 事实 同 原审 。\n",
      "[['再审', '查明', '的', '犯罪', '事实', '同', '原审']]\n",
      "1839\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "2669\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "2758\n",
      "审理 查明 的 事实 与 公诉 机关 起诉 的 事实 相 同 。\n",
      "[['审理', '查明', '的', '事实', '与', '公诉', '机关', '起诉', '的', '事实', '相同']]\n",
      "2936\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "4634\n",
      "的 事实 、 罪名 及 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '及', '提交', '的', '证据', '均', '无', '异议']]\n",
      "6871\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "8580\n",
      "的 犯罪 事实 与 庭审 查明 的 基本 事实 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '基本', '事实', '一致']]\n",
      "10172\n",
      "原审 认定 的 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "13006\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "13672\n",
      "的 事实 、 罪名 及 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '及', '提交', '的', '证据', '均', '无', '异议']]\n",
      "18550\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "20691\n",
      "再审 查明 的 事实 与 原审 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '一致']]\n",
      "20999\n",
      "的 事实 、 罪名 、 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '、', '提交', '的', '证据', '均', '无', '异议']]\n",
      "21096\n",
      "再审 查明 的 事实 与 原审 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '一致']]\n",
      "21634\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "23479\n",
      "原审 判决 认定 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '判决', '认定', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "25353\n",
      "的 事实 与 起诉书 指控 事实 一致 。\n",
      "[['的', '事实', '与', '起诉书', '指控', '事实', '一致']]\n",
      "25986\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "26293\n",
      "的 事实 、 罪名 及 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '及', '提交', '的', '证据', '均', '无', '异议']]\n",
      "28621\n",
      "上述 事实 经 当庭 举证 、 质证 ，\n",
      "[['上述', '事实', '经', '当庭', '举证', '、', '质证', '，']]\n",
      "28908\n",
      "被告人 孙 某某 犯×× 罪 。\n",
      "[['被告人', '孙', '某某', '犯××', '罪']]\n",
      "31752\n",
      "被告人 潘某 犯×× 罪 。 建议 依照 《 中华人民共和国刑法 》 ×× 之 规定 惩处 。\n",
      "[['被告人', '潘某', '犯××', '罪'], ['建议', '依照', '《', '中华人民共和国刑法', '》', '××', '之', '规定', '惩处']]\n",
      "32393\n",
      "的\n",
      "[['的']]\n",
      "32877\n",
      "原审 认定 的 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "35370\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "39915\n",
      "\n",
      "[]\n",
      "42999\n",
      "\n",
      "[]\n",
      "43066\n",
      "原判 认定 的\n",
      "[['原判', '认定', '的']]\n",
      "44178\n",
      "本院 审理 查明 事实 与 原判 认定 事实 一致 。 本院 认定\n",
      "[['本院', '审理', '查明', '事实', '与', '原判', '认定', '事实', '一致'], ['本院', '认定']]\n",
      "45631\n",
      "本院 审理 查明 的 事实 与 一审 查明 的 事实 一致 。\n",
      "[['本院', '审理', '查明', '的', '事实', '与', '一审', '查明', '的', '事实', '一致']]\n",
      "47401\n",
      "的 罪名 和 犯罪 事实 无 异议 。\n",
      "[['的', '罪名', '和', '犯罪', '事实', '无', '异议']]\n",
      "50264\n",
      "的 事实 与 起诉书 指控 的 事实 一致 。\n",
      "[['的', '事实', '与', '起诉书', '指控', '的', '事实', '一致']]\n",
      "51379\n",
      "被告人 王某 甲犯 ×× 罪 。\n",
      "[['被告人', '王某', '甲犯', '××', '罪']]\n",
      "52803\n",
      "的 罪名 和 犯罪事 与 本院 认定 的 犯罪 事实 基本 一致 。\n",
      "[['的', '罪名', '和', '犯罪事', '与', '本院', '认定', '的', '犯罪', '事实', '基本', '一致']]\n",
      "53017\n",
      "的 罪名 和 犯罪 事实 均 无 异议 。\n",
      "[['的', '罪名', '和', '犯罪', '事实', '均', '无', '异议']]\n",
      "53605\n",
      "被告人 赵某 甲犯 包庇罪 。\n",
      "[['被告人', '赵某', '甲犯', '包庇罪']]\n",
      "55951\n",
      "事实 及 证据 亦 无 异议 。\n",
      "[['事实', '及', '证据', '亦', '无', '异议']]\n",
      "57121\n",
      "\n",
      "[]\n",
      "57726\n",
      "的 罪名 和 犯罪 事实 均 无 异议 。\n",
      "[['的', '罪名', '和', '犯罪', '事实', '均', '无', '异议']]\n",
      "58753\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "58921\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "62330\n",
      "的 犯罪 事实 一致 。\n",
      "[['的', '犯罪', '事实', '一致']]\n",
      "62636\n",
      "的 犯罪 事实 客观 存在 ，\n",
      "[['的', '犯罪', '事实', '客观', '存在', '，']]\n",
      "64392\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "64624\n",
      "原审 判决 认定 的\n",
      "[['原审', '判决', '认定', '的']]\n",
      "64773\n",
      "本院 认定\n",
      "[['本院', '认定']]\n",
      "68618\n",
      "被告人 胡某 的 行为 构成 ×× 罪 。\n",
      "[['被告人', '胡某', '的', '行为', '构成', '××', '罪']]\n",
      "70537\n",
      "原 判决 认定 的 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原', '判决', '认定', '的', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "71984\n",
      "再审 查明 的 事实 与 原审 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '一致']]\n",
      "72161\n",
      "原审 认定 的 事实 清楚 ， 证据 确实 充分 ， 应 予 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '，', '证据', '确实', '充分', '，', '应', '予', '确认']]\n",
      "72273\n",
      "的 事实 和 证据 与 原判 相同 。\n",
      "[['的', '事实', '和', '证据', '与', '原判', '相同']]\n",
      "75098\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "75525\n",
      "\n",
      "[]\n",
      "79779\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "82175\n",
      "再审 查明 的 事实 与 原审 判决 认定 的 事实 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '判决', '认定', '的', '事实', '一致']]\n",
      "82216\n",
      "\n",
      "[]\n",
      "82831\n",
      "\n",
      "[]\n",
      "83190\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "83449\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "88604\n",
      "经 本院 审理 查明 ， 原判 认定 的\n",
      "[['经', '本院', '审理', '查明', '，', '原判', '认定', '的']]\n",
      "89777\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "91464\n",
      "96467\n",
      "train_dataset is processed over\n",
      "\n",
      "\n",
      "[]\n",
      "908\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "1149\n",
      "原审 判决 认定 的 事实 清楚 ， 本院 予以 确认 。 证明\n",
      "[['原审', '判决', '认定', '的', '事实', '清楚', '，', '本院', '予以', '确认'], ['证明']]\n",
      "3738\n",
      "原判 认定 的 事实 清楚 ， 证据 确实 ， 本院 予以 确认 。\n",
      "[['原判', '认定', '的', '事实', '清楚', '，', '证据', '确实', '，', '本院', '予以', '确认']]\n",
      "3779\n",
      "原判 认定 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原判', '认定', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "3847\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "4136\n",
      "\n",
      "[]\n",
      "5254\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "6502\n",
      "原审 认定 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "7828\n",
      "\n",
      "[]\n",
      "8311\n",
      "原判 认定 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原判', '认定', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "8313\n",
      "经 再审 查明 的 事实 与 原审 基本 一致 ， 本院 予以 确认 。\n",
      "[['经', '再审', '查明', '的', '事实', '与', '原审', '基本', '一致', '，', '本院', '予以', '确认']]\n",
      "9315\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "10088\n",
      "\n",
      "[]\n",
      "10481\n",
      "原审 认定 的 事实 清楚 、 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '、', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "10992\n",
      "被告人 屈某 犯 贷款 诈骗罪 ， 诈骗 本息 共计 58412 4 . 75 元 。\n",
      "[['被告人', '屈某', '犯', '贷款诈骗罪', '，', '诈骗', '本息', '共计', '58412', '4', '.', '75', '元']]\n",
      "11875\n",
      "\n",
      "[]\n",
      "12350\n",
      "\n",
      "[]\n",
      "12882\n",
      "12878\n",
      "valid_dataset is processed over\n",
      "\n",
      "的 事实 、 证据 与 原判 认定 的 一致 ， 本院 予以 确认 。\n",
      "[['的', '事实', '、', '证据', '与', '原判', '认定', '的', '一致', '，', '本院', '予以', '确认']]\n",
      "796\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "2009\n",
      "事实 无 异议 ， 愿 认罪 服法 。\n",
      "[['事实', '无', '异议', '，', '愿', '认罪', '服法']]\n",
      "3639\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "3810\n",
      "的 犯罪 事实 客观 存在 ，\n",
      "[['的', '犯罪', '事实', '客观', '存在', '，']]\n",
      "5045\n",
      "\n",
      "[]\n",
      "5117\n",
      "的 事实 、 证据 与 原审 判决 相同 。\n",
      "[['的', '事实', '、', '证据', '与', '原审', '判决', '相同']]\n",
      "5120\n",
      "\n",
      "[]\n",
      "5762\n",
      "\n",
      "[]\n",
      "5827\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "12240\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "12768\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "13332\n",
      "\n",
      "[]\n",
      "13492\n",
      "原审 认定 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "19560\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "21082\n",
      "\n",
      "[]\n",
      "23522\n",
      "24819\n",
      "test_dataset is processed over\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/w2id_thulac.pkl', 'rb') as f:\n",
    "    word2id_dict = pk.load(f)\n",
    "    f.close()\n",
    "\n",
    "file_list = ['train', 'valid', 'test']\n",
    "cut = get_cutter(stop_words_filtered= False)\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    fact_lists = []\n",
    "    law_label_lists = []\n",
    "    accu_label_lists = []\n",
    "    term_lists = []\n",
    "    num = 0\n",
    "\n",
    "    with open('../data/{}_cs.json'.format(file_list[i]), 'r', encoding= 'utf-8') as f:\n",
    "        idx = 0\n",
    "        for line in f.readlines():\n",
    "            idx += 1\n",
    "            line = json.loads(line)\n",
    "            fact = line['fact_cut']\n",
    "            sentence, word_num, sent_words = sentence2index_matrix(fact, word2id_dict, doc_len, sent_len, cut)\n",
    "\n",
    "            if word_num <= 10:\n",
    "                print(fact)\n",
    "                print(sent_words)\n",
    "                print(idx)\n",
    "                continue\n",
    "\n",
    "            fact_lists.append(sentence)\n",
    "            law_label_lists.append(line['law'])\n",
    "            accu_label_lists.append(line['accu'])\n",
    "            term_lists.append(line['term'])\n",
    "            num += 1\n",
    "        f.close()\n",
    "    data_dict = {'fact_list': fact_lists, 'law_label_lists': law_label_lists, 'accu_label_lists': accu_label_lists, 'term_lists': term_lists}\n",
    "    pk.dump(data_dict, open('./{}_processed_thulac_Legal_basis.pkl'.format(file_list[i]), 'wb'))\n",
    "    print(num)\n",
    "    print('{}_dataset is processed over'.format(file_list[i])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
