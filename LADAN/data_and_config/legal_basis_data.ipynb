{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12de3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thulac\n",
    "import jieba\n",
    "import json\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "add_punc='，。、【 】 “”：；（）《》‘’{}？！⑦()、%^>℃：.”“^-——=&#@￥'\n",
    "all_punc = punctuation + add_punc\n",
    "doc_len = 15\n",
    "sent_len = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22d90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除文本中标点符号\n",
    "def punc_delete(fact_list):\n",
    "    fact_filtered = []\n",
    "    for word in fact_list:\n",
    "        fact_filtered.append(word)\n",
    "        if word in all_punc:\n",
    "            fact_filtered.remove(word)\n",
    "    return fact_filtered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02e77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hanzi_to_num(hanzi_1):\n",
    "    # for num<10000\n",
    "    hanzi = hanzi_1.strip().replace('零', '')\n",
    "    if hanzi == '':\n",
    "        return str(int(0))\n",
    "    d = {'一': 1, '二': 2, '三': 3, '四': 4, '五': 5, '六': 6, '七': 7, '八': 8, '九': 9, '': 0}\n",
    "    m = {'十': 1e1, '百': 1e2, '千': 1e3, }\n",
    "    w = {'万': 1e4, '亿': 1e8}\n",
    "    res = 0\n",
    "    tmp = 0\n",
    "    thou = 0\n",
    "    for i in hanzi:\n",
    "        if i not in d.keys() and i not in m.keys() and i not in w.keys():\n",
    "            return hanzi\n",
    "\n",
    "    if (hanzi[0]) == '十': hanzi = '一' + hanzi\n",
    "    for i in range(len(hanzi)):\n",
    "        if hanzi[i] in d:\n",
    "            tmp += d[hanzi[i]]\n",
    "        elif hanzi[i] in m:\n",
    "            tmp *= m[hanzi[i]]\n",
    "            res += tmp\n",
    "            tmp = 0\n",
    "        else:\n",
    "            thou += (res + tmp) * w[hanzi[i]]\n",
    "            tmp = 0\n",
    "            res = 0\n",
    "    return int(thou + res + tmp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d553f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "def get_cutter(dict_path=\"D://大四上学期/NLP/MyLADAN/data_and_config/law_processed/Thuocl_seg.txt\", mode='thulac', stop_words_filtered=True):\n",
    "    if stop_words_filtered:\n",
    "        stopwords = stopwordslist('D://大四上学期/NLP/MyLADAN/data_and_config/law_processed/stop_word.txt')  # 这里加载停用词的路径\n",
    "    else:\n",
    "        stopwords = [] \n",
    "    if mode == 'jieba':\n",
    "        jieba.load_userdict(dict_path)\n",
    "        return lambda x: [a for a in list(jieba.cut(x)) if a not in stopwords]\n",
    "    elif mode == 'thulac':\n",
    "        thu = thulac.thulac(user_dict=dict_path, seg_only=True)\n",
    "        return lambda x: [a for a in thu.cut(x, text=True).split(' ') if a not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1922cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_sentence(sentence, cut):\n",
    "    # cut=get_cutter()\n",
    "    # sentence_seged = thu.cut(sentence.strip(), text=True).split(' ')\n",
    "    sentence_seged = cut(sentence)\n",
    "    # print(sentence_seged)\n",
    "    outstr = []\n",
    "    for word in sentence_seged:\n",
    "        if word != '\\t':\n",
    "            word = str(hanzi_to_num(word))\n",
    "            outstr.append(word)\n",
    "            # outstr += \" \"\n",
    "    return outstr\n",
    "\n",
    "\n",
    "def lookup_index_for_sentences(sentences, word2id, doc_len, sent_len):\n",
    "    item_num = 0\n",
    "    res = []\n",
    "    if len(sentences) == 0:\n",
    "        tmp = [word2id['BLANK']] * sent_len\n",
    "        res.append(np.array(tmp))\n",
    "    else:\n",
    "        for sent in sentences:\n",
    "            sent = punc_delete(sent)\n",
    "            tmp = [word2id['BLANK']] * sent_len\n",
    "            for i in range(len(sent)):\n",
    "                if i >= sent_len:\n",
    "                    break\n",
    "                try:\n",
    "                    tmp[i] = word2id[sent[i]]\n",
    "                    item_num += 1\n",
    "                except KeyError:\n",
    "                    tmp[i] = word2id['UNK']\n",
    "\n",
    "            res.append(np.array(tmp))\n",
    "    if len(res) < doc_len:\n",
    "        res = np.concatenate([np.array(res), word2id['BLANK'] * np.ones([doc_len - len(res), sent_len], dtype=np.int)], 0)\n",
    "    else:\n",
    "        res = np.array(res[:doc_len])\n",
    "\n",
    "    return res, item_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff95cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2index_matrix(sentence, word2id, doc_len, sent_len, cut):\n",
    "    sentence = sentence.replace(' ', '')\n",
    "    sent_words, sent_n_words = [], []\n",
    "    for i in sentence.split('。'):\n",
    "        if i != '':\n",
    "            sent_words.append((seg_sentence(i, cut)))\n",
    "    index_matrix, item_num = lookup_index_for_sentences(sent_words, word2id, doc_len, sent_len)\n",
    "    return index_matrix, item_num, sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ded5089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n"
     ]
    }
   ],
   "source": [
    "with open('D://大四上学期/NLP/MyLADAN/data_and_config/data/w2id_thulac.pkl', 'rb') as f:\n",
    "    word2id_dict = pk.load(f)\n",
    "    f.close()\n",
    "\n",
    "file_list = ['train', 'valid', 'test']\n",
    "cut = get_cutter(stop_words_filtered= False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23687e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0493cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "1013\n",
      "再审 查明 的 犯罪 事实 同 原审 。\n",
      "[['再审', '查明', '的', '犯罪', '事实', '同', '原审']]\n",
      "1856\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "2883\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "3011\n",
      "审理 查明 的 事实 与 公诉 机关 起诉 的 事实 相 同 。\n",
      "[['审理', '查明', '的', '事实', '与', '公诉', '机关', '起诉', '的', '事实', '相同']]\n",
      "3248\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "5585\n",
      "的 事实 、 罪名 及 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '及', '提交', '的', '证据', '均', '无', '异议']]\n",
      "7936\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "9650\n",
      "的 犯罪 事实 与 庭审 查明 的 基本 事实 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '基本', '事实', '一致']]\n",
      "11264\n",
      "原审 认定 的 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "14202\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "14972\n",
      "本院 审理 查明 的 事实 和 认定 依据 ， 与 原判 相同 。\n",
      "[['本院', '审理', '查明', '的', '事实', '和', '认定', '依据', '，', '与', '原判', '相同']]\n",
      "16401\n",
      "的 事实 、 罪名 及 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '及', '提交', '的', '证据', '均', '无', '异议']]\n",
      "20658\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "23024\n",
      "再审 查明 的 事实 与 原审 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '一致']]\n",
      "23344\n",
      "的 事实 、 罪名 、 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '、', '提交', '的', '证据', '均', '无', '异议']]\n",
      "23443\n",
      "再审 查明 的 事实 与 原审 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '一致']]\n",
      "24016\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "25937\n",
      "原审 判决 认定 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '判决', '认定', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "27882\n",
      "的 事实 与 起诉书 指控 事实 一致 。\n",
      "[['的', '事实', '与', '起诉书', '指控', '事实', '一致']]\n",
      "28539\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "28856\n",
      "的 事实 、 罪名 及 提交 的 证据 均 无 异议 。\n",
      "[['的', '事实', '、', '罪名', '及', '提交', '的', '证据', '均', '无', '异议']]\n",
      "31284\n",
      "上述 事实 经 当庭 举证 、 质证 ，\n",
      "[['上述', '事实', '经', '当庭', '举证', '、', '质证', '，']]\n",
      "31588\n",
      "被告人 孙 某某 犯×× 。\n",
      "[['被告人', '孙', '某某', '犯××']]\n",
      "34527\n",
      "被告人 潘某 犯×× 。 建议 依照 《 中华人民共和国刑法 》 ×× 之 规定 惩处 。\n",
      "[['被告人', '潘某', '犯××'], ['建议', '依照', '《', '中华人民共和国刑法', '》', '××', '之', '规定', '惩处']]\n",
      "35196\n",
      "的\n",
      "[['的']]\n",
      "35705\n",
      "原审 认定 的 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "38310\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "43049\n",
      "\n",
      "[]\n",
      "46200\n",
      "\n",
      "[]\n",
      "46267\n",
      "原判 认定 的\n",
      "[['原判', '认定', '的']]\n",
      "47401\n",
      "本院 审理 查明 事实 与 原判 认定 事实 一致 。 本院 认定\n",
      "[['本院', '审理', '查明', '事实', '与', '原判', '认定', '事实', '一致'], ['本院', '认定']]\n",
      "48887\n",
      "本院 审理 查明 的 事实 与 一审 查明 的 事实 一致 。\n",
      "[['本院', '审理', '查明', '的', '事实', '与', '一审', '查明', '的', '事实', '一致']]\n",
      "50701\n",
      "的 罪名 和 犯罪 事实 无 异议 。\n",
      "[['的', '罪名', '和', '犯罪', '事实', '无', '异议']]\n",
      "53643\n",
      "的 事实 与 起诉书 指控 的 事实 一致 。\n",
      "[['的', '事实', '与', '起诉书', '指控', '的', '事实', '一致']]\n",
      "54791\n",
      "被告人 王某 甲犯 ×× 。\n",
      "[['被告人', '王某', '甲犯', '××']]\n",
      "56256\n",
      "的 罪名 和 犯罪事 与 本院 认定 的 犯罪 事实 基本 一致 。\n",
      "[['的', '罪名', '和', '犯罪事', '与', '本院', '认定', '的', '犯罪', '事实', '基本', '一致']]\n",
      "56477\n",
      "的 罪名 和 犯罪 事实 均 无 异议 。\n",
      "[['的', '罪名', '和', '犯罪', '事实', '均', '无', '异议']]\n",
      "57083\n",
      "被告人 赵某 甲犯 包庇罪 。\n",
      "[['被告人', '赵某', '甲犯', '包庇罪']]\n",
      "59501\n",
      "事实 及 证据 亦 无 异议 。\n",
      "[['事实', '及', '证据', '亦', '无', '异议']]\n",
      "60704\n",
      "\n",
      "[]\n",
      "61332\n",
      "的 罪名 和 犯罪 事实 均 无 异议 。\n",
      "[['的', '罪名', '和', '犯罪', '事实', '均', '无', '异议']]\n",
      "62394\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "62564\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "66089\n",
      "的 犯罪 事实 一致 。\n",
      "[['的', '犯罪', '事实', '一致']]\n",
      "66407\n",
      "的 犯罪 事实 客观 存在 ，\n",
      "[['的', '犯罪', '事实', '客观', '存在', '，']]\n",
      "68223\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "68463\n",
      "与 原审 相同 ， 没有 提供 新 的 证据 ， 也 没有 新 的 公诉 意见 。\n",
      "[['与', '原审', '相同', '，', '没有', '提供', '新', '的', '证据', '，', '也', '没有', '新', '的', '公诉', '意见']]\n",
      "68588\n",
      "原审 判决 认定 的\n",
      "[['原审', '判决', '认定', '的']]\n",
      "68618\n",
      "本院 认定\n",
      "[['本院', '认定']]\n",
      "72598\n",
      "被告人 胡某 的 行为 构成 ×× 。\n",
      "[['被告人', '胡某', '的', '行为', '构成', '××']]\n",
      "74581\n",
      "原 判决 认定 的 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原', '判决', '认定', '的', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "76079\n",
      "再审 查明 的 事实 与 原审 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '一致']]\n",
      "76260\n",
      "原审 认定 的 事实 清楚 ， 证据 确实 充分 ， 应 予 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '，', '证据', '确实', '充分', '，', '应', '予', '确认']]\n",
      "76378\n",
      "的 事实 和 证据 与 原判 相同 。\n",
      "[['的', '事实', '和', '证据', '与', '原判', '相同']]\n",
      "79307\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "79753\n",
      "\n",
      "[]\n",
      "84197\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "86683\n",
      "再审 查明 的 事实 与 原审 判决 认定 的 事实 一致 。\n",
      "[['再审', '查明', '的', '事实', '与', '原审', '判决', '认定', '的', '事实', '一致']]\n",
      "86726\n",
      "\n",
      "[]\n",
      "87369\n",
      "\n",
      "[]\n",
      "87739\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "88003\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "93360\n",
      "经 本院 审理 查明 ， 原判 认定 的\n",
      "[['经', '本院', '审理', '查明', '，', '原判', '认定', '的']]\n",
      "94583\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "96351\n",
      "原判 认定 原审 被告人 郭某 犯×× 的 事实 正确 。\n",
      "[['原判', '认定', '原审', '被告人', '郭某', '犯××', '的', '事实', '正确']]\n",
      "96966\n",
      "101608\n",
      "train_dataset is processed over\n",
      "\n",
      "\n",
      "[]\n",
      "912\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "1162\n",
      "\n",
      "[]\n",
      "1983\n",
      "原审 判决 认定 的 事实 清楚 ， 本院 予以 确认 。 证明\n",
      "[['原审', '判决', '认定', '的', '事实', '清楚', '，', '本院', '予以', '确认'], ['证明']]\n",
      "4160\n",
      "原判 认定 的 事实 清楚 ， 证据 确实 ， 本院 予以 确认 。\n",
      "[['原判', '认定', '的', '事实', '清楚', '，', '证据', '确实', '，', '本院', '予以', '确认']]\n",
      "4201\n",
      "原判 认定 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原判', '认定', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "4269\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "4662\n",
      "\n",
      "[]\n",
      "5818\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "7152\n",
      "原审 认定 事实 清楚 ， 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '事实', '清楚', '，', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "8496\n",
      "\n",
      "[]\n",
      "8997\n",
      "原判 认定 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原判', '认定', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "8999\n",
      "经 再审 查明 的 事实 与 原审 基本 一致 ， 本院 予以 确认 。\n",
      "[['经', '再审', '查明', '的', '事实', '与', '原审', '基本', '一致', '，', '本院', '予以', '确认']]\n",
      "10045\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "10838\n",
      "\n",
      "[]\n",
      "11240\n",
      "原审 认定 的 事实 清楚 、 证据 确实 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '的', '事实', '清楚', '、', '证据', '确实', '充分', '，', '本院', '予以', '确认']]\n",
      "11764\n",
      "被告人 屈某 犯 贷款 诈骗罪 ， 诈骗 本息 共计 58412 4 . 75 元 。\n",
      "[['被告人', '屈某', '犯', '贷款诈骗罪', '，', '诈骗', '本息', '共计', '58412', '4', '.', '75', '元']]\n",
      "12690\n",
      "\n",
      "[]\n",
      "13183\n",
      "\n",
      "[]\n",
      "13764\n",
      "13762\n",
      "valid_dataset is processed over\n",
      "\n",
      "的 事实 、 证据 与 原判 认定 的 一致 ， 本院 予以 确认 。\n",
      "[['的', '事实', '、', '证据', '与', '原判', '认定', '的', '一致', '，', '本院', '予以', '确认']]\n",
      "804\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "2031\n",
      "事实 无 异议 ， 愿 认罪 服法 。\n",
      "[['事实', '无', '异议', '，', '愿', '认罪', '服法']]\n",
      "3747\n",
      "的 犯罪 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '犯罪', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "3955\n",
      "的 犯罪 事实 客观 存在 ，\n",
      "[['的', '犯罪', '事实', '客观', '存在', '，']]\n",
      "5344\n",
      "\n",
      "[]\n",
      "5428\n",
      "的 事实 、 证据 与 原审 判决 相同 。\n",
      "[['的', '事实', '、', '证据', '与', '原审', '判决', '相同']]\n",
      "5431\n",
      "\n",
      "[]\n",
      "6133\n",
      "\n",
      "[]\n",
      "6205\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "13593\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "14155\n",
      "的 事实 与 庭审 查明 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '庭审', '查明', '的', '事实', '基本', '一致']]\n",
      "14749\n",
      "\n",
      "[]\n",
      "14913\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "18682\n",
      "原审 认定 事实 清楚 ， 证据 确实 、 充分 ， 本院 予以 确认 。\n",
      "[['原审', '认定', '事实', '清楚', '，', '证据', '确实', '、', '充分', '，', '本院', '予以', '确认']]\n",
      "21238\n",
      "的 事实 与 本院 认定 的 事实 基本 一致 。\n",
      "[['的', '事实', '与', '本院', '认定', '的', '事实', '基本', '一致']]\n",
      "22808\n",
      "\n",
      "[]\n",
      "25378\n",
      "26741\n",
      "test_dataset is processed over\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(file_list)):\n",
    "    fact_lists = []\n",
    "    law_label_lists = []\n",
    "    accu_label_lists = []\n",
    "    term_lists = []\n",
    "    num = 0\n",
    "\n",
    "    with open('D://大四上学期/NLP/MyLADAN/new_file/{}_cs.json'.format(file_list[i]), 'r', encoding= 'utf-8') as f:\n",
    "        idx = 0\n",
    "        for line in f.readlines():\n",
    "            idx += 1\n",
    "            line = json.loads(line)\n",
    "            fact = line['fact_cut']\n",
    "            sentence, word_num, sent_words = sentence2index_matrix(fact, word2id_dict, doc_len, sent_len, cut)\n",
    "\n",
    "            if word_num <= 10:\n",
    "                print(fact)\n",
    "                print(sent_words)\n",
    "                print(idx)\n",
    "                continue\n",
    "\n",
    "            fact_lists.append(sentence)\n",
    "            law_label_lists.append(line['law'])\n",
    "            accu_label_lists.append(line['accu'])\n",
    "            term_lists.append(line['term'])\n",
    "            num += 1\n",
    "        f.close()\n",
    "    data_dict = {'fact_list': fact_lists, 'law_label_lists': law_label_lists, 'accu_label_lists': accu_label_lists, 'term_lists': term_lists}\n",
    "    pk.dump(data_dict, open('D://大四上学期/NLP/MyLADAN/new_file/{}_processed_thulac_Legal_basis.pkl'.format(file_list[i]), 'wb'))\n",
    "    print(num) \n",
    "    print('{}_dataset is processed over'.format(file_list[i])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0d190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OldLADAN",
   "language": "python",
   "name": "oldladan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
